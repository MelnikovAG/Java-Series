# 内存溢出

内存溢出是指应用新建一个对象实例时，所需的内存空间大于堆的可用空间。内存溢出的种类较多，一般会在报错日志里看到 OutOfMemoryError 关键字。常见内存溢出种类及分析思路如下：

- java.lang.OutOfMemoryError: Java heap space。原因：堆中（新生代和老年代）无法继续分配对象了、某些对象的引用长期被持有没有被释放，垃圾回收器无法回收、使用了大量的 Finalizer 对象，这些对象并不在 GC 的回收周期内等。一般堆溢出都是由于内存泄漏引起的，如果确认没有内存泄漏，可以适当通过增大堆内存。

- java.lang.OutOfMemoryError: GC overhead limit exceeded。原因：垃圾回收器超过 98%的时间用来垃圾回收，但回收不到 2%的堆内存，一般是因为存在内存泄漏或堆空间过小。

- java.lang.OutOfMemoryError: Metaspace 或 java.lang.OutOfMemoryError: PermGen space。排查思路：检查是否有动态的类加载但没有及时卸载，是否有大量的字符串常量池化，永久代/元空间是否设置过小等。

- java.lang.OutOfMemoryError: unable to create new native Thread。原因：虚拟机在拓展栈空间时，无法申请到足够的内存空间。可适当降低每个线程栈的大小以及应用整体的线程个数。此外，系统里总体的进程/线程创建总数也受到系统空闲内存和操作系统的限制，请仔细检查。注：这种栈溢出，和 StackOverflowError 不同，后者是由于方法调用层次太深，分配的栈内存不够新建栈帧导致。

此外，还有 Swap 分区溢出、本地方法栈溢出、数组分配溢出等 OutOfMemoryError 类型。

一般来说，对于很多学了好几年，甚至于很多年 java 人来说，一旦看到 OutOfMemeory(简称 OOM)，就认为 HeapSize 不够，然后疯狂的增加-Xmx 的值，但是 HeapSize 只是其中一个部分，当你去做一 个实验，也就是 java 启动时直接在程序中疯狂的 new 一些线程出来，直到内存溢出，当-Xms -Xmx 设置得越大的时候，得到的线程个数会越少，为什么呢？因为 OOM 并不是 HeapSize 不够而导致的，而由很多种情况。

首先看下操作系统如何划分内存给应用系统，其实在 Win 32、Linux 32 的系统中，地址总线为 32 位的理论上应该可以支持 4G 内存空间，但是当你在 Win 32 上设置初始化内存如果达到 2G，就会报错，说这个块空间没法做，首先默认的 Win32 系统，会按照 50%比例给予给 Kernel 使用，而另一部分给应 用内存，也就是说操作系统内核部分不论是否使用，这一半是不会给你的，而还有 2G 呢，它在系统扩展的部分，也就是并非 Kernel 的部分，有很多静态区域 和字典表的内容，所以要划分一个连续的 2G 内存给 JVM 在 Win 32 上是不可能的，Win 32 提出了一种 Win 32 3G 模式，貌似可以划分 3G 空间，其实它只是将内核部分缩小也就是管理部分缩小，也就是将一部分划分到外部来使用，而且 Win 32 习惯在内存 2G 的位置做一些手脚，让你分配连续 2G 没有可能性，一般来说在 Win 32 平台上，在物理内存足够的情况下给 JVM 划分的空间一般是 1.4~1.5G 左右，具体数据没有测试过；而 Linux 32 类似于 Win 32 3G 模式，但是它还是一般情况下分布不凌乱的情况下，一般可以给 JVM 划分到 2G 的大小。Linux 32 Hugemem 是一个扩展版本，可以划分更大的空间，但是需要付出一些其他的代价，理论上可以支持到 4G 给应用，也就是 Kenel 是独立 的；Solaris x86-32 和 AIX 32 等系统，也类似于 Linux 32 平台一样。

为什么还要预留一些空间出来呢？这些空间给谁？
当你申请一个线程的时候，它的除了线程内部对象的开销外，线程本身的开销，是需要 OS 来调度完成，一般来说，会在 OS 的线程与虚拟机内部有都有一个一一对 应的，但是会根据操作系统不同有所变化，有些可能只有一个，总之 heapSize 外的那部分空间是跑不掉的，它放在哪里呢？就是放在 Stack 中的，所以 上文中的-Xss 就是设置这个的，在 jdk 1.5 以后，每个线程的大小被默认设置为 1M 的 stack 开销，我们习惯将这个开销降低。

好了知道了指针、线程是在 heapSize 外部的，还有什么呢？
当你自己使用 native 方法，也就是 JNI 的时候，调用本地其他语言，如 C、C++在程序中使用了 malloc 等类似方法开辟的内存，都不是在 heapSize 中的，而是在本地 OS 所掌控的，另外这部分空间如果没有相应的释放命令，就需要在对应 finalize 方法内部调用其他的 native 方 法来完成对相应对象的释放，否则这部分将成为 OS 级别的内存泄露，直到 JVM 进程重启或者宕机为止(操作系统会记录下进程和相应线程和堆内存的关联关系，但是进程再没有释放前，OS 也是不会回收这部分内存的)。
另外在使用 JavaNIO 以及 JDBC、流等系列操作时，当形成与终端交互时，会在另一个位置形成一个内存区域，这些内存区域都不在 HeapSize 中。
所以常见的 OOM 现象有以下几种：
1、heapSize 溢出，这个需要设置 Java 虚拟机的内存情况
2、PermSize 溢出，需要设置 Perm 相关参数以及检查内存中的常量情况。
3、OS 地址空间不够，也就是没有那么多内存分配，这个一般是启动时报错。
4、Swap 空间频繁交互，进程直接被 crash 掉，在不同操作系统中会体现不同的情况。
5、native Thread 溢出，注意线程 Stack 的大小，以及本身操作系统的限制。
6、DirectByteBuffer 溢出，这一类一般是在做一些 NIO 操作的时 候，或在某种情况下使用 ByteBuffer，在分配内存时使用了 allocateDirect 以及使用一些框架间接调用了类似方法，导致直接内存的分配 (如 mina 中使用 IoByte 去调用，当参数设置为 true 的时候就分配为直接内存，所谓直接内存就是又 OS 定义的内存，而不需要从程序间接拷贝一次再 输出的过程，提高性能，但是如果没有手动回收是回收不掉的)，导致的 Buffer 问题，如输出大量的内容，输入大量的内容，此时需要尽量去尝试限制它的大 小。

使用非常多的工具区检测 Java 的内存如：jstat(只能看 HeapSize 和 PermSize)、jmap(很细的东西)、jps(java 的 ps -ef 呵呵)、jdb(这个不是监控工具哈，这个是 debug 工具)、jprofile(图形支持，但是可以远程连接)等等；jconsole(可以看到 heapsize、permsize+native mem size(这这里叫做：non-heapsize)等等的使用的趋势图)、visualvm(极为推荐的东西，图形化查看，你可以查看到内存单元分配、交 换、回收、移动等等整个过程，非常清晰展现 jvm 的全局资源)、另外 pmap 可以展现非常清晰的资料，可以精确到某一个 java 进程内部的每一个细节，而 且可以看到 heapsize 只是其中很小一部分(在 solaris 操作系统上看得最齐全，LINUX 下有些进程可能看不太懂)；也可以在/proc/进程 号/maps 中查看(这里可以看到内存地址单元的起始地址，包含了 reserved 的地址范围和 commited 的地址范围)，全局资源使用操作系统 top 命令和 free 命令看；IBM 有一个 GCMV 免费下载工具也很好；Win32 有一个 WMMap 工具都是很好的工具

使用相应的工具观察相应的内容，当观察到内存的使用从无到有，上升，然后处于一个平稳 趋势，那么这个 JVM 应该是较为稳定的；如果发现它经过一段平滑期后，又出现飙升，这个必然是有问题的，至于什么问题，根据前面的学下和实际情况我们可以 去分析；当它开始后，平滑过程，出现缓慢上升的过程，但是始终会上升到极点，那么一个是需要知道物理内存时候可用，另一个就是少量的内存泄露(JVM 现代 也有内存泄露，只是它的内存泄露并非 C、C++中的内存泄露)。

```
Heap
 PSYoungGen      total 343552K, used 335874K [0x000000076ab00000, 0x0000000793000000, 0x00000007c0000000)
  eden space 149504K, 100% used [0x000000076ab00000,0x0000000773d00000,0x0000000773d00000)
  from space 194048K, 96% used [0x0000000781900000,0x000000078cf00a88,0x000000078d680000)
  to   space 225280K, 0% used [0x0000000773d00000,0x0000000773d00000,0x0000000781900000)
 ParOldGen       total 705024K, used 476040K [0x00000006c0000000, 0x00000006eb080000, 0x000000076ab00000)
  object space 705024K, 67% used [0x00000006c0000000,0x00000006dd0e2290,0x00000006eb080000)
 Metaspace       used 3194K, capacity 4494K, committed 4864K, reserved 1056768K
  class space    used 345K, capacity 386K, committed 512K, reserved 1048576K
```

      我曾经在文章中说到任何系统最多使用的数据类型必然是String，不管做什么，所以在String的处理上很有研究，推荐使用java的朋友在大量使用 对比的时候不要用equals，而推荐使用intern()，但是我最近发现我错了，我这里给大家道歉，因为可能会误导很多朋友；下面说明下这个东西为什 么？
     首先我开始自己怀疑自己的时候是想说，如果intern可以做到高效，那么equals是不是在String中就没有存在的必要了呢，当时对于我理解仅仅 为常量池的一个地址对比，好比是两个数字的compare，仅仅需要CPU的单个指令即可完成；于是我开始做了两个实验，一个是最原始，最初级的方法采用 单线程循环1000000次调用equals与intern等值对比，并且采用了不同长度的字符串去做比较，发现equals竟然比intern要快，而 且随着字符串长度的增加，equals会明显快与intern，然后使用多线程测试也是得到一样的效果，我首先很不敢相信自己坚持的理论被彻底和谐了，后 来冷静下来必须需要面对，通过很多权威资料的阅读，我发现我对JVM常量池的理解还只是一点点皮毛而已，所以我做了更加深入的研究。
    原来intern方法被调用时是在Perm中的String私有化常量池中寻找相应的内容，而寻找虽然可以通过hash定位到某些较小的链表中，但是还是 需要在链表中逐个对比，对比的方法仍然是equals，也就是抛开hash的开销，intern最少要与里面的0到多个对象进行equals操作，而且如 果不存在，还要在常量池开辟一块空间来记录，如果存在则返回地址，也就是常量池保证每个String常量是唯一的，这个开销当然大了，而且如果使用在业务 代码中将会导致Perm区域的不断增加；
    于是，我又反过来想了：既然equals比他效率高，为啥还要用intern呢？而且equals的那个算法对于长字符串逐个字符对比的过程我实在是难以 入目；而且也实在是觉得不甘心自己的理论就这么容易被和谐掉，因为自己已经在不少程序中这样用过，这样我岂不是犯下大错了，因为自己参与过的项目的确太多 了，而且有类似的代码我写入了框架中，最终发现我可能错了一半，也就是历史上的记录可能我有一半类似的代码是错误的；为什么呢？intern还是有用的，我先做了一个测试，那就是，用一个已经intern好的对象，让他与一个常量做等值，循环次数和上面一样，结果我预料的结果发生了，那就是比equals 快出了N多倍数，随着长度的增加，会体现出更加明显的优势，因为intern对比的始终是地址，和长度无关，于是我想到了如何使用它，就是在程序中返回通 过字符串类似于数字一样的类型判定时，如：做一个sqlparser的时候，经常根据数据类型做不同的动作，这样如果用equals会在每次循环时付出很 多开销，尤其是很多数据库的类型非常多，最坏的是从上到下每个字符串匹配一次，当然长度不等开销很小，长度相等开销就大了；intern我就将这些 schema信息预先intern掉，也就是他们已经指向了常量池，当再真正匹配时，就不需要用intern了，而是直接匹配，也就是将这个开销放在初始 化的过程中，运行时我们不去增加它的开销。
    所以，个人是犯下一个错误，并且以前还很张扬的到处宣传，呵呵，现在觉得有点傻，希望在看到某些推荐用什么新东西的时候，千万不要在没有研究明白他就去用 它，甚至于滥用它，至少要经过一些简单的测试，不过对于现代很多复杂的东西，一些简单的测试已经不足以说明问题，就像Lock与Synchronize的 开销一样，如果采用简单的循环的话，你会发现新版本的Lock的开销将会比Synchronized的开销更加大，它适合的是并发，读写的并发，所以真正 要弄清楚还是研究内在。
