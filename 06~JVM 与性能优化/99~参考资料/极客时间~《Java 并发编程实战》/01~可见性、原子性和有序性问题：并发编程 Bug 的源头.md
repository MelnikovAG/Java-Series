# 可见性、原子性和有序性问题：并发编程 Bug 的源头

随着技术的进步，CPU、内存和 I/O 设备的性能都在持续提升，但它们之间的速度差异仍然是一个长期存在的挑战。为了最大限度地发挥 CPU 的高速度优势，同时解决速度不匹配的问题，计算机体系结构、操作系统和编译器都采取了一系列措施来平衡这三者之间的速度差异。这些措施主要包括：

- CPU 增加了缓存，以均衡与内存的速度差异；
- 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
- 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。”

# 源头之一：缓存导致的可见性问题

在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。

![CPU 缓存与内存的关系](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/XuBwWhSGLJ4k.png)

一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。

![多核 CPU 的缓存与内存关系图](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/nlfYzNKEd2sC.png)

```java
public class Test {
  private long count = 0;

  private void add10K() {
    int idx = 0;
    while(idx++ < 10000) {
      count += 1;
    }
  }

  public static long calc() {
    final Test test = new Test();

    // 创建两个线程，执⾏ add() 操作
    Thread th1 = new Thread(()->{
      test.add10K();
    });
    Thread th2 = new Thread(()->{
      test.add10K()
    });
    // 启动两个线程
    th1.start();
    th2.start();
    // 等待两个线程执⾏结束
    th1.join();
    th2.join();
    return count;
  }
}
```

假设线程 A 和线程 B 同时启动，它们首先将初始值为 0 的共享变量 count 读取到各自 CPU 的缓存中。当它们各自执行 count += 1 操作后，每个线程的缓存中的 count 值变为 1。如果这两个线程几乎同时将更新后的值写回主内存，最终在内存中的 count 值将是 1 而不是预期的 2。这是因为每个线程都看不到对方缓存中的更新。

接下来，由于每个线程的 CPU 缓存中已经有了 count 的值，它们将继续基于各自缓存中的值进行计算，导致最终 count 的值小于预期。如果将 count += 1 操作循环执行 1 亿次，由于缓存可见性问题，最终 count 的值会接近 1 亿而不是 2 亿。如果循环执行 10000 次，count 的值会接近 20000，这表明线程启动存在微小的时间差，导致它们不是完全同时执行。

![变量 count 在 CPU 缓存和内存的分布图](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/zMRRBqlhO1xO.png)

# 源头之二：线程切换带来的原子性问题

操作系统允许某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个 50 毫秒称为“时间片”。

![线程切换示意图](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/EApAFXG2I9LM.png)

在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。这里的进程在等待 IO 时之所以会释放 CPU 使用权，是为了让 CPU 在这段等待时间里可以做别的事情，这样一来 CPU 的使用率就上来了；此外，如果这时有另外一个进程也读文件，读文件的操作就会排队，磁盘驱动在完成一个进程的读操作后，发现有排队的任务，就会立即启动下一个读操作，这样 IO 的使用率也上来了。

在早期操作系统中，CPU 调度是基于进程进行的，进程之间不共享内存空间，因此进程间的切换需要重新加载内存映射，这增加了任务切换的开销。相比之下，同一进程中的线程共享相同的内存空间，这使得线程间的切换成本较低。当代操作系统倾向于使用更轻量级的线程进行 CPU 调度，因此我们通常所说的“任务切换”实际上指的是“线程切换”。在 Java 等高级语言编写的并发程序中，线程切换是常见的，但可能很少有人意识到，线程切换的时机和方式也可能是并发编程中出现诡异 Bug 的原因之一。

线程切换通常发生在操作系统的时间片到期时。在高级语言中，一个简单的语句，如 count += 1，在底层可能需要执行多条 CPU 指令来完成。这意味着，如果在执行这条语句的过程中发生线程切换，可能会导致部分操作未完成，从而引发并发问题。例如上面代码中的 count += 1，至少需要三条 CPU 指令。

- 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
- 指令 2：之后，在寄存器中执行 +1 操作；
- 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

操作系统做任务切换，可以发生在任何一条 CPU 指令执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。

![非原子操作的执行路径示意图](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/xLuhAGYoqLDN.png)

我们潜意识里面觉得 count+=1 这个操作是一个不可分割的整体，就像一个原子一样，线程的切换可以发生在 count+=1 之前，也可以发生在 count+=1 之后，但就是不会发生在中间。我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。因此，很多时候我们需要在高级语言层面保证操作的原子性。

# 源头之三：编译优化带来的有序性问题

顾名思义，有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的 Bug。在 Java 领域一个经典的案例就是利用双重检查创建单例对象，例如下面的代码：在获取实例 getInstance() 的方法中，我们首先判断 instance 是否为空，如果为空，则锁定 Singleton.class 并再次检查 instance 是否为空，如果还为空则创建 Singleton 的一个实例。

```java
public class Singleton {
  static Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}
```

假设有两个线程 A、B 同时调用 getInstance() 方法，他们会同时发现 instance == null ，于是同时对 Singleton.class 加锁，此时 JVM 保证只有一个线程能够加锁成功（假设是线程 A），另外一个线程则会处于等待状态（假设是线程 B）；线程 A 会创建一个 Singleton 实例，之后释放锁，锁释放后，线程 B 被唤醒，线程 B 再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程 B 检查 instance == null 时会发现，已经创建过 Singleton 实例了，所以线程 B 不会再创建一个 Singleton 实例。

这看上去一切都很完美，无懈可击，但实际上这个 getInstance() 方法并不完美。问题出在哪里呢？出在 new 操作上，我们以为的 new 操作应该是：

- 分配一块内存 M；
- 在内存 M 上初始化 Singleton 对象；
- 然后 M 的地址赋值给 instance 变量。

但是实际上优化后的执行路径却是这样的：

- 分配一块内存 M；
- 将 M 的地址赋值给 instance 变量；
- 最后在内存 M 上初始化 Singleton 对象；

![双重检查创建单例的异常执行路径](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/uPic/eE32sjWVHalI.png)

优化后会导致什么问题呢？我们假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 instance != null ，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。
